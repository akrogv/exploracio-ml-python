# Natural Language Processing with Disaster Tweets
We are asked to analyze wether a given tweet is a real disaster or not, this is a good competition to start messing around with NLP for a number of factors starting with the size of the dataset that enables relatively fast training and thus provides time to try different approaches and techniques to further optimize performance.

## Dataset information
Two csv files are provided (train and test) and each file has 3 columns that contain the tweet, a keyword from the tweet (with null values) and the location (with null values also) with the training dataset containing the target class with the values 0 and 1.

The columns are the following:
- id - a unique identifier for each tweet
- text - the text of the tweet
- location - the location the tweet was sent from (may be blank)
- keyword - a particular keyword from the tweet (may be blank)
- target - in train.csv only, this denotes whether a tweet is about a real disaster (1) or not (0)

## Things to learn
As said in the first section, we could try many aproaches to the problem cause of it's relatively small size and also there are many very interesting tools to process the data into a model that we could explore.

## Difficulties & Timing
I think we could do quite well in this problem although i may be throwing from three here ;) .

This competition is ongoing forever. It doesn't give points whatsoever.

## Score
### **6/10**
Could be cool as a first project but it even might be short for that purpose.